# Research: Mejores PrÃ¡cticas para Comandos Slash en Claude Code

**Fecha**: 2025-10-08
**Investigador**: @library-researcher
**Contexto**: OptimizaciÃ³n de comandos slash personalizados para invocar agentes de manera eficiente

---

## ğŸ“š Fuentes de InvestigaciÃ³n

### DocumentaciÃ³n Oficial

- **Claude Docs - Slash Commands**: https://docs.claude.com/en/docs/claude-code/slash-commands
- **Claude Code GitHub Issues**: https://github.com/anthropics/claude-code/issues/4745
- **Dev.to Guide**: Claude Code Part 4 - Slash Commands and Custom Commands

### AnÃ¡lisis de CÃ³digo Existente

- `.claude/commands/init-project.md` (1864 lÃ­neas) - Comando complejo con orquestaciÃ³n
- `.claude/commands/prp/prp-story-task-create.md` (143 lÃ­neas) - Comando de research
- `.claude/commands/prp/prp-story-task-execute.md` (187 lÃ­neas) - Comando de ejecuciÃ³n
- `.claude/agents/task-planner.md` - Sistema de coordinaciÃ³n de agentes
- `.claude/agents/prp-expert.md` - Especialista en PRPs con delegaciÃ³n

---

## ğŸ¯ Hallazgos Clave

### 1. **Estructura de Archivos Slash Command**

**ENCONTRADO**: Los comandos slash son archivos Markdown en `.claude/commands/` con frontmatter.

**AnatomÃ­a de un Comando**:

````markdown
---
description: "DescripciÃ³n corta que aparece en /help y en tool description"
allowed-tools: ["Read", "Write", "Edit", "Bash"] # Opcional: restringir tools
argument-hint: "path/to/file" # Opcional: hint para argumentos
model: "sonnet" # Opcional: modelo especÃ­fico
disable-model-invocation: false # Opcional: prevenir ejecuciÃ³n automÃ¡tica
---

# Command: nombre-comando

DescripciÃ³n detallada del comando

## Usage

```bash
/nombre-comando [argumentos]
```
````

## Arguments

- `$ARGUMENTS` - Todos los argumentos como string
- `$1`, `$2`, etc. - Argumentos individuales

## Contenido del Comando

[Instrucciones especÃ­ficas para Claude sobre quÃ© hacer cuando se invoca el comando]

````

**CRÃTICO**: La `description` en frontmatter es lo que Claude ve cuando decide si usar el comando via SlashCommand tool.

---

### 2. **Frontmatter y Metadatos**

**OPCIONES DE FRONTMATTER**:

```yaml
---
# REQUERIDO para SlashCommand tool
description: "Breve descripciÃ³n (1 lÃ­nea, max 100 chars)"

# OPCIONAL pero recomendado
argument-hint: "file.md"  # Muestra quÃ© espera el comando
model: "sonnet"           # Usar modelo especÃ­fico (sonnet/opus/haiku)

# CONTROL DE EJECUCIÃ“N
disable-model-invocation: false  # Si true, previene auto-ejecuciÃ³n

# RESTRICCIÃ“N DE HERRAMIENTAS
allowed-tools:
  - "Read"
  - "Write"
  - "Bash"
  - "Task"  # CRÃTICO: Incluir Task si comando invoca agentes
---
````

**BEST PRACTICE**:

- **Descripciones cortas**: Max 100 caracteres, clara y accionable
- **`allowed-tools` explÃ­cito**: Siempre incluir `Task` si el comando invoca agentes
- **`argument-hint`**: Ayuda a Claude entender quÃ© parÃ¡metros esperar

---

### 3. **InvocaciÃ³n de Agentes desde Comandos**

**PATRÃ“N DESCUBIERTO**: Claude Code NO tiene una API directa para invocar agentes. Los agentes se invocan IMPLÃCITAMENTE a travÃ©s del contenido del comando.

**MECANISMO REAL**:

1. **Usuario ejecuta comando**: `/mi-comando arg1 arg2`
2. **Claude lee el archivo markdown**: `.claude/commands/mi-comando.md`
3. **Claude sigue las instrucciones**: El markdown contiene instrucciones que MENCIONAN agentes
4. **Claude decide invocar agentes**: Basado en el contexto y las instrucciones

**PATRÃ“N INCORRECTO** (No funciona):

```markdown
# âŒ NO EXISTE una API directa tipo:

@invoke-agent("library-researcher", query="...")
```

**PATRÃ“N CORRECTO** (Funciona):

```markdown
# âœ… Instrucciones que GUÃAN a Claude a usar agentes:

## Mission

Research JWT best practices by:

1. **Use @library-researcher** to find official documentation:
   - Query: "JWT authentication best practices security"
   - Focus: Official docs, security considerations, gotchas

2. **Use @codebase-analyst** IN PARALLEL to analyze existing patterns:
   - Find: Authentication patterns in codebase
   - Extract: Naming conventions, structure patterns

3. **WAIT for both agents** to complete before proceeding

4. **Consolidate findings** from both agents
```

**HALLAZGO CRÃTICO**: Los agentes se invocan mediante **instrucciones en lenguaje natural**, NO mediante llamadas a funciones.

---

### 4. **OrquestaciÃ³n Multi-Agente en Comandos**

**PATRÃ“N ENCONTRADO en `/init-project`**:

Los comandos complejos actÃºan como **ORCHESTRADORES** que:

1. **Definen estrategia de agentes** (cuÃ¡les usar, en quÃ© orden)
2. **Instruyen ejecuciÃ³n paralela** cuando es seguro
3. **Esperan resultados** antes de continuar
4. **Consolidan outputs** de mÃºltiples agentes

**EJEMPLO REAL de `/init-project`** (lÃ­neas 170-223):

```markdown
### **Fase 0.5: AnÃ¡lisis y GestiÃ³n de Agentes**

**OBLIGATORIO antes de crear el proyecto:**

1. ANALIZAR AGENTES EXISTENTES:

   "ğŸ¤– Analizando agentes disponibles...

   Leyendo: .claude/agents/"

   [Lee todos los archivos .md en .claude/agents/]

   Agentes encontrados:
   - codebase-analyst.md: Analiza patrones de cÃ³digo
   - library-researcher.md: Investiga librerÃ­as
   - [otros agentes...]

2. EVALUAR RELEVANCIA:

   [Usa @mcp__server-sequential-thinking__sequentialthinking]

   "Evaluando quÃ© agentes son Ãºtiles para tu proyecto:

   ğŸ“Š AnÃ¡lisis de relevancia:

   âœ… ÃšTILES para este proyecto:
   - codebase-analyst: Necesario para [razÃ³n especÃ­fica]
   - library-researcher: Necesario para [razÃ³n especÃ­fica]

   âš ï¸ PARCIALMENTE ÃšTILES (necesitan adaptaciÃ³n):
   - [agente-x]: Ãštil pero requiere [modificaciÃ³n]

   âŒ NO RELEVANTES:
   - [agente-y]: No aplica para este tipo de proyecto
```

**BEST PRACTICE**:

- **Fase 0**: Analizar quÃ© agentes existen (leer `.claude/agents/`)
- **Fase 1**: Decidir cuÃ¡les usar (Sequential Thinking ayuda)
- **Fase 2**: Definir estrategia de delegaciÃ³n (quiÃ©n hace quÃ©)
- **Fase 3**: Ejecutar en paralelo o secuencial segÃºn dependencias
- **Fase 4**: Consolidar resultados

---

### 5. **EjecuciÃ³n Paralela vs Secuencial**

**PATRÃ“N DESCUBIERTO en `/init-project`** (lÃ­neas 280-325):

```markdown
### **OrquestaciÃ³n Paralela de Agentes**

Durante la creaciÃ³n del proyecto, el orquestador usa agentes en paralelo:
```

Ejemplo - Fase de AnÃ¡lisis:

"ğŸ”„ Ejecutando anÃ¡lisis paralelo con 3 agentes...

[PARALELO]
â”œâ”€â”€> @sequential-thinking
â”‚ â””â”€> Analizando arquitectura del proyecto...
â”‚
â”œâ”€â”€> @library-researcher
â”‚ â””â”€> Investigando mejores librerÃ­as para Gmail API...
â”‚
â””â”€â”€> @codebase-analyst
â””â”€> Buscando patrones similares en proyectos existentes...

[ESPERAR RESULTADOS]

âœ… AnÃ¡lisis completado (3/3 agentes)

ğŸ“Š Resultados consolidados:
[...]

```

```

**CUÃNDO USAR PARALELO**:

- âœ… Agentes trabajan en **datos diferentes** (ej: uno research externo, otro patterns internos)
- âœ… No hay **dependencias entre outputs**
- âœ… Pueden **fallar independientemente** sin afectar al otro

**CUÃNDO USAR SECUENCIAL**:

- âŒ Output del agente A es **input del agente B**
- âŒ Agente B necesita **decisiÃ³n humana** del output de A
- âŒ Orden importa para **coherencia**

**SINTAXIS PARA INDICAR PARALELISMO**:

```markdown
## Phase 1: Research (PARALELO)

Execute these agents IN PARALLEL:

**Agent 1: @library-researcher**

- Query: [...]
- MCPs: tavily-search, WebFetch
- Duration: ~15 min

**Agent 2: @codebase-analyst**

- Query: [...]
- MCPs: serena find_symbol, search_for_pattern
- Duration: ~10 min

**WAIT** for BOTH agents to complete before Phase 2.

## Phase 2: Consolidation (SECUENCIAL)

After Phase 1 completes:

1. Analyze findings from @library-researcher
2. Analyze findings from @codebase-analyst
3. Synthesize recommendations
```

---

### 6. **Checkpoints y ValidaciÃ³n Humana**

**HALLAZGO CRÃTICO**: Los mejores comandos incluyen **CHECKPOINTS explÃ­citos** donde Claude DEBE esperar aprobaciÃ³n humana.

**PATRÃ“N ENCONTRADO en `task-planner.md`** (CHECKPOINT 1 y 2):

```markdown
### âœ… CHECKPOINT 1: Research Validation (ROI 100x)

**CRITICAL**: NEVER skip this checkpoint. ROI is 100x.

**Present research findings to user:**
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” RESEARCH PHASE COMPLETE (CHECKPOINT 1)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[... summary de research ...]

âš ï¸ CRITICAL VALIDATION QUESTIONS:

1. Does the recommended approach align with your vision?
2. Are there any gotchas we missed?
3. Do you have answers to the open questions?
4. Should we research anything else before planning?
5. Is this direction correct?

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Options:
âœ… "approve" - Research is solid, proceed to planning
ğŸ”„ "fix: [description]" - Research needs adjustment
âŒ "restart" - Wrong direction, redo research
â“ "answer: [answers to questions]" - Provide missing info
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**WAIT FOR USER RESPONSE** - Do NOT proceed without approval.

```

**IMPORTANT**:
- **WAIT** for user to respond with "approve", "fix", "restart", or "answer"
- **NEVER assume** user approves
- **NEVER skip** this checkpoint - ROI is 100x
```

**BEST PRACTICE para CHECKPOINTS**:

1. **Presentar resumen claro** con viÃ±etas
2. **Hacer preguntas crÃ­ticas** que requieren decisiÃ³n humana
3. **Ofrecer opciones explÃ­citas**: approve / fix / restart
4. **WAIT FOR USER RESPONSE** - nunca continuar sin respuesta
5. **Documentar decisiÃ³n** en memoria o planning doc

**CUÃNDO INCLUIR CHECKPOINTS**:

- âœ… DespuÃ©s de **research phase** (ROI 100x - previene 1000s lÃ­neas mal dirigidas)
- âœ… DespuÃ©s de **planning phase** (ROI 10-20x - previene 10-100 lÃ­neas re-trabajo)
- âœ… Antes de **decisiones arquitectÃ³nicas** irreversibles
- âœ… Antes de **ejecutar cambios destructivos** (eliminaciÃ³n de cÃ³digo, migraciÃ³n)

---

### 7. **Manejo de Contexto y Referencias**

**HALLAZGO**: Los comandos que invocan agentes deben pasar **contexto completo** porque agentes NO tienen acceso al historial del usuario.

**PATRÃ“N ENCONTRADO en `/prp-story-task-create`** (lÃ­neas 19-23):

```markdown
## Mission

Transform a user story or task into a **tactical implementation PRP** through systematic codebase analysis and task decomposition.

We do not write any code in this step, the goal is to create a detailed context-engineered implementation plan for the implementation agent.

**Key Principle**: We must first gather the context about the story/task before proceeding with the analysis.

When we understand the story/task, we can proceed with the codebase analysis. We systematically dig deep into the codebase to gather intelligence and identify patterns and implementation points. We then use this information to create a PRP that can be executed by a coding agent.

**The contents of the created PRP should encapsulate all the information the agent needs to complete the story/task in one pass.**

Remember that subagents will only receive details from you; the user cannot interact with them directly. Therefore, include all relevant context in the subagent prompt and TODO.
```

**BEST PRACTICE**:

- **Pasar TODA la info necesaria**: User story, archivos relevantes, decisiones tomadas
- **No asumir conocimiento previo**: Agentes solo ven lo que el comando les pasa
- **Usar `$ARGUMENTS` para datos del usuario**: `/comando user-story-aquÃ­`
- **Referenciar archivos explÃ­citamente**: "Analyze src/auth/oauth.py lines 45-67"

**PATRÃ“N DE PASO DE CONTEXTO**:

```markdown
## Step 2: Invoke @library-researcher

**Context to pass**:

- **User Goal**: $ARGUMENTS (from command invocation)
- **Tech Stack**: [Language/Framework discovered in Step 1]
- **Existing Patterns**: [Patterns from @codebase-analyst]
- **Constraints**: [Any constraints user mentioned]

**Query for agent**:
"Research best practices for JWT authentication in [Language/Framework].

Context:

- User wants to implement: $ARGUMENTS
- Project uses: [tech stack]
- Existing auth patterns: [summary]

Find:

1. Recommended libraries (with security considerations)
2. Implementation best practices
3. Common gotchas and how to avoid them
4. Testing strategies

Focus on: Production-ready patterns, not hello-world examples."
```

---

### 8. **GestiÃ³n de Errores y Fallbacks**

**PATRÃ“N ENCONTRADO en `/prp-story-task-execute`** (lÃ­neas 132-146):

```markdown
## Manejo de Fallos

Cuando una tarea falla validaciÃ³n:

1. Leer mensaje de error cuidadosamente
2. Verificar referencia de patrÃ³n nuevamente en fases implementadas
3. Validar investigando el codebase del Sistema
4. Arreglar y re-validar
5. Si atascado, verificar implementaciones similares en Phase 1-3
6. Revisar errores comunes documentados en CLAUDE.md:
   - Bucles infinitos (status incorrecto)
   - SerializaciÃ³n Redis (usar BaseModel)
   - Imports cross-phase (sys.path.append)
```

**BEST PRACTICE para ERROR HANDLING en comandos**:

```markdown
## Error Handling Strategy

If [operation] fails:

### Step 1: Diagnose

- Read error message carefully
- Identify which phase/task failed
- Check logs/output for root cause

### Step 2: Consult Memory

- Use @archon-expert to query: "similar error: [error type]"
- Check if this error is documented in `.claude/memories/`

### Step 3: Attempt Fix

- Apply known solution if available
- Otherwise, analyze with @sequential-thinking:
  - What went wrong?
  - What are possible causes?
  - What are potential fixes?

### Step 4: Retry with Validation

- Apply fix
- Re-run validation command
- Verify error is resolved

### Step 5: Document Solution (if new)

- Store in `.claude/memories/` via @archon-expert
- Update relevant documentation
- Add to troubleshooting section

**FALLBACK**: If stuck after 3 retries:

- Present error to user with analysis
- Ask for guidance
- Options: ["debug together", "skip and continue", "restart phase"]
```

---

### 9. **SlashCommand Tool (InvocaciÃ³n ProgramÃ¡tica)**

**HALLAZGO IMPORTANTE**: Claude puede invocar comandos slash **programÃ¡ticamente** usando el tool `SlashCommand`.

**DOCUMENTACIÃ“N OFICIAL**:

```
The SlashCommand tool allows Claude to execute custom slash commands
programmatically during a conversation.
```

**CUÃNDO SE USA**:

- Claude decide que un comando es relevante para la tarea actual
- Solo si el comando tiene `description` en frontmatter
- Solo comandos permitidos (no en disable list)

**LIMITACIONES**:

- **Budget de 15,000 caracteres**: El comando expandido no puede exceder este lÃ­mite
- **Sin interactividad**: Comandos invocados programÃ¡ticamente NO pueden pedir input intermedio
- **Ejecuta TODO el comando**: No hay control granular de quÃ© partes ejecutar

**ISSUE DESCUBIERTO** (GitHub #4745):

- Algunos comandos estÃ¡n siendo ejecutados automÃ¡ticamente via SlashCommand tool cuando NO deberÃ­an
- Rompe flujos interactivos que esperan input del usuario
- **Workaround temporal**: Usar `disable-model-invocation: true` en frontmatter

**BEST PRACTICE**:

- **Comandos cortos (<15k chars)**: OK para invocaciÃ³n automÃ¡tica
- **Comandos interactivos**: Agregar `disable-model-invocation: true` hasta que issue se resuelva
- **Comandos de orquestaciÃ³n**: Mejor invocar manualmente `/comando arg`

---

### 10. **Naming Conventions y Namespacing**

**PATRÃ“N ENCONTRADO**:

Los comandos pueden organizarse en **namespaces** usando directorios:

```
.claude/commands/
â”œâ”€â”€ init-project.md          â†’ /init-project
â”œâ”€â”€ update-context.md        â†’ /update-context
â””â”€â”€ prp/                     â†’ Namespace "prp:"
    â”œâ”€â”€ prp-story-task-create.md     â†’ /prp:prp-story-task-create
    â”œâ”€â”€ prp-story-task-execute.md    â†’ /prp:prp-story-task-execute
    â””â”€â”€ prp-validate.md              â†’ /prp:prp-validate
```

**NAMING BEST PRACTICES**:

- **Kebab-case**: `mi-comando.md` â†’ `/mi-comando`
- **Namespaces con `:``**: Carpeta `prp/` â†’ comandos con prefijo `/prp:`
- **Nombres descriptivos**: `/create-feature-prp` mejor que `/cfp`
- **Verbos al inicio**: `/create-*`, `/execute-*`, `/validate-*`

---

## ğŸ¨ Patrones Recomendados

### **PatrÃ³n 1: Comando Simple de Research**

**Caso de uso**: Research de una biblioteca especÃ­fica

````markdown
---
description: "Research [library] best practices and integration patterns"
argument-hint: "library-name"
---

# Command: research-library

## Usage

```bash
/research-library jwt
```
````

## Mission

Research implementation-critical documentation for $ARGUMENTS library.

## Process

### Step 1: Use @library-researcher

Query: "Research $ARGUMENTS best practices, security considerations, gotchas"

Focus:

- Official documentation
- Production-ready patterns
- Security implications
- Common pitfalls

### Step 2: Use @archon-expert (Parallel)

Query RAG knowledge base: "previous implementations using $ARGUMENTS"

### Step 3: Consolidate Findings

Create document: `/research/research_$ARGUMENTS.md`

Include:

- Best practices discovered
- Recommended approach
- Critical gotchas
- Integration examples

### Step 4: Present to User

Show findings summary and ask for approval before using in implementation.

````

---

### **PatrÃ³n 2: Comando de OrquestaciÃ³n Multi-Fase**

**Caso de uso**: CreaciÃ³n de feature completa con checkpoints

```markdown
---
description: "Create and execute complete feature implementation with checkpoints"
argument-hint: "feature-description"
allowed-tools: ["Read", "Write", "Edit", "Bash", "Task", "TodoWrite"]
---

# Command: create-feature

## Usage
```bash
/create-feature "Add payment processing with Stripe"
````

## Mission

Implement complete feature with research â†’ planning â†’ implementation â†’ validation flow.

## Process (4 Phases with 2 Checkpoints)

### Phase 1: Research (45-60 min, PARALLEL)

**Invoke BOTH agents in parallel:**

#### Agent 1: @library-researcher

- Research: External best practices for feature
- Duration: ~30 min
- MCPs: tavily-search, WebFetch, perplexity-ask

#### Agent 2: @codebase-analyst

- Analyze: Internal patterns for similar features
- Duration: ~20 min
- MCPs: serena find_symbol, search_for_pattern

**WAIT** for both agents to complete.

**Output**: Create `/research/research_[feature].md`

### âœ… CHECKPOINT 1: Research Validation (ROI 100x)

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” RESEARCH COMPLETE - CHECKPOINT 1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Summary: [Consolidated findings from both agents]

Critical Questions:
1. Is the recommended approach correct?
2. Any missing considerations?
3. Should we proceed to planning?

Options: approve / fix: [desc] / restart

**WAIT FOR USER RESPONSE**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Phase 2: Planning (30-45 min)

Use @task-planner with Sequential Thinking:

- Decompose feature into atomic tasks
- Define validation strategy
- Estimate time
- Identify dependencies

**Output**: Create `/planning/planning_[feature].md`

### âœ… CHECKPOINT 2: Planning Validation (ROI 10-20x)

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ PLANNING COMPLETE - CHECKPOINT 2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Summary: [Task breakdown, file structure, estimates]

Critical Questions:
1. Does file structure make sense?
2. Are tasks atomic enough?
3. Time estimates realistic?

Options: approve / fix: [desc] / restart

**WAIT FOR USER RESPONSE**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Phase 3: TDD Implementation (2-4 hours)

Delegate to @task-executor:

- Execute plan from Phase 2
- TDD approach (tests FIRST)
- Validate after EACH task
- Track progress with TodoList

### Phase 4: Final Validation (30 min)

Use @validation-gates:

- Level 1: Syntax/style
- Level 2: Unit tests
- Level 3: Integration tests
- Level 4: Build

**Success**: All levels pass â†’ Feature complete âœ…

````

---

### **PatrÃ³n 3: Comando de ValidaciÃ³n Standalone**

**Caso de uso**: Validar PRPs, cÃ³digo, o documentaciÃ³n

```markdown
---
description: "Validate [artifact] using [criteria]"
argument-hint: "path/to/artifact.md"
---

# Command: validate-prp

## Usage
```bash
/validate-prp PRPs/story_auth.md
````

## Mission

Validate PRP using Pareto 80-20 scoring criteria.

## Process

### Step 1: Read PRP

Read file: $1

### Step 2: Use @prp-validator

Invoke agent with PRP contents:

- Score using Pareto 80-20 (80 critical + 20 nice-to-have)
- Tier 1 (80 pts): Current vs Desired, Mixed References, Specific Logic, Actionable Steps
- Tier 2 (20 pts): Validation gates, Clear constraints

### Step 3: Present Results

If score >= 80:

```
âœ… VALIDATION PASSED (Score: [X]/100)

The PRP meets critical requirements and is ready for execution.

Breakdown:
- Tier 1 Critical: [X]/80 pts
- Tier 2 High: [X]/20 pts

Strengths: [list]
Suggestions: [optional improvements]
```

If score < 80:

```
âš ï¸ VALIDATION FAILED (Score: [X]/100)

The PRP needs improvement before execution.

Issues Found:
- [Issue 1]: [Description] (-[Y] pts)
- [Issue 2]: [Description] (-[Z] pts)

Recommended Fixes:
1. [Fix for issue 1]
2. [Fix for issue 2]

Auto-improve? (yes/no)
```

### Step 4: Auto-Improvement Loop (if requested)

If user says "yes":

- Apply fixes using @prp-expert
- Re-validate
- Max 3 iterations
- If stuck after 3: Request manual review

### Step 5: Backup & Document

- Create backup: `[file].backup-[timestamp]`
- Document validation in: `/validation/validation_[file]_[date].md`

````

---

### **PatrÃ³n 4: Comando de Setup Interactivo**

**Caso de uso**: Configurar API, servicio, o herramienta paso a paso

```markdown
---
description: "Setup [service] with interactive step-by-step guidance"
argument-hint: "service-name"
disable-model-invocation: true  # Prevent auto-execution (interactive)
---

# Command: setup-service

## Usage
```bash
/setup-service stripe
````

## Mission

Guide user through $ARGUMENTS setup with interactive validation.

## Philosophy

**NEVER**: Dump 50 steps â†’ User gets lost
**ALWAYS**: Step â†’ Validate â†’ Confirm â†’ Next step

## Process

### Step 1: Research Service

Use @library-researcher:

- Query: "$ARGUMENTS setup guide official documentation"
- Find: Step-by-step setup instructions
- Extract: Required credentials, configuration

**Output**: List of setup steps with exact URLs

### Step 2: Interactive Setup Loop

For each setup step:

```
ğŸ“¡ $ARGUMENTS Setup - Step [N]/[TOTAL]

[Step description]

1ï¸âƒ£ Go to: [EXACT URL]

2ï¸âƒ£ [Specific action]

3ï¸âƒ£ [Next action]

âœ… Done? (yes/no/error: [message])
```

**WAIT** for user response.

If "yes": Continue to next step
If "no": Ask "What went wrong?"
If "error: [msg]": Debug error, provide solution, retry

### Step 3: Validate Configuration

After all steps complete:

```bash
# Test $ARGUMENTS connection
[validation command]
```

Expected output: [describe expected result]

Did you see this? (yes/no)

### Step 4: Celebrate & Document

If validation passes:

```
ğŸ‰ $ARGUMENTS completely configured!

âœ… Summary:
   - [Step 1] âœ“
   - [Step 2] âœ“
   - [Step 3] âœ“
   - Validation passed âœ“

Next: [What user can do now]
```

Update documentation:

- Add setup to README.md
- Add env vars to .env.example
- Create usage guide in docs/

````

---

## ğŸ“‹ Recomendaciones EspecÃ­ficas por Tipo de Comando

### **Comandos de Research**

**CaracterÃ­sticas**:
- Deben invocar @library-researcher (externo) + @codebase-analyst (interno)
- EjecuciÃ³n en **PARALELO** para eficiencia
- Generar documento `/research/research_[topic].md`
- Incluir CHECKPOINT con findings para validaciÃ³n humana

**Template**:
```markdown
---
description: "Research [topic] with parallel external + internal analysis"
argument-hint: "topic"
---

# Research [Topic]

## Phase 1: Parallel Research (15-30 min)

[PARALELO]
â”œâ”€> @library-researcher: External best practices
â””â”€> @codebase-analyst: Internal patterns

## Phase 2: Consolidate

Combine findings from both agents

## âœ… CHECKPOINT: Present findings

WAIT FOR APPROVAL before using in implementation
````

---

### **Comandos de Planning**

**CaracterÃ­sticas**:

- Deben usar **Sequential Thinking** (8-15 adaptive thoughts)
- Generar YAML plan estructurado
- Incluir validation strategy
- Definir checkpoints humanos
- Generar documento `/planning/planning_[feature].md`

**Template**:

```markdown
---
description: "Plan [feature] with Sequential Thinking and structured output"
argument-hint: "feature-description"
allowed-tools: ["Task", "TodoWrite"]
---

# Plan [Feature]

## Phase 1: Sequential Thinking Analysis

Use @mcp**server-sequential-thinking**sequentialthinking:

- Thought 1-3: Understand scope
- Thought 4-7: Identify dependencies
- Thought 8-12: Design approach
- Thought 13-15: Validate coherence

## Phase 2: Generate YAML Plan

Structure:

- Phases with tasks
- Dependencies
- Validation commands
- Checkpoints

## âœ… CHECKPOINT: Validate Plan

Present plan for approval with critical questions
```

---

### **Comandos de Execution**

**CaracterÃ­sticas**:

- Deben usar **TDD approach** (tests FIRST)
- Invocar @validation-gates **despuÃ©s de CADA cambio**
- Track progress con TodoWrite tool
- Handle errors con retry logic
- Document deviations from plan

**Template**:

```markdown
---
description: "Execute [plan] with TDD and continuous validation"
argument-hint: "path/to/plan.md"
allowed-tools: ["Read", "Write", "Edit", "Bash", "TodoWrite", "Task"]
---

# Execute [Plan]

## Phase 1: Load Plan

Read: $1

## Phase 2: Task-by-Task Execution

For each task:

1. Write failing test (TDD)
2. Implement minimum code
3. Run test (should pass)
4. Invoke @validation-gates
5. Mark task complete in TodoList
6. ONLY proceed if validation passes

## Phase 3: Final Validation

@validation-gates full suite:

- Level 1: Syntax
- Level 2: Style
- Level 3: Tests
- Level 4: Build

## Phase 4: Document Completion

Move plan to completed/
Update relevant docs
```

---

### **Comandos de Validation**

**CaracterÃ­sticas**:

- Deben tener **criterios claros de pass/fail**
- Generar **validation reports**
- Ofrecer **auto-improvement** cuando falla
- Limitar iterations (max 3) para evitar loops infinitos

**Template**:

```markdown
---
description: "Validate [artifact] using [criteria]"
argument-hint: "path/to/artifact"
---

# Validate [Artifact]

## Step 1: Load Artifact

Read: $1

## Step 2: Apply Validation Criteria

Check:

- [ ] Criterion 1 (critical)
- [ ] Criterion 2 (critical)
- [ ] Criterion 3 (nice-to-have)

Score: [X]/100 (80 critical + 20 nice-to-have)

## Step 3: Report Results

If pass (>=80): âœ… Report strengths, optional improvements
If fail (<80): âš ï¸ Report issues, recommended fixes

## Step 4: Auto-Improvement (Optional)

If user approves:

- Apply fixes
- Re-validate
- Max 3 iterations
- Document all changes
```

---

### **Comandos Interactivos**

**CaracterÃ­sticas**:

- Deben tener `disable-model-invocation: true` (hasta que issue #4745 se resuelva)
- **WAIT FOR USER** despuÃ©s de cada paso crÃ­tico
- Ofrecer opciones claras: yes/no/error
- Include **debugging guidance** cuando falla
- **Celebrar pequeÃ±os logros** para mantener motivaciÃ³n

**Template**:

```markdown
---
description: "Setup [service] with interactive step-by-step guidance"
disable-model-invocation: true
---

# Interactive Setup: [Service]

## Philosophy

NEVER: Dump all steps
ALWAYS: Step â†’ Validate â†’ Confirm â†’ Next

## Loop Pattern

For each step:
```

[N]/[TOTAL]: [Step description]

1ï¸âƒ£ Action: [Specific instruction]
2ï¸âƒ£ Go to: [EXACT URL if applicable]
3ï¸âƒ£ Expected result: [What user should see]

âœ… Done? (yes/no/error: [msg])

```

WAIT for response

If yes: Next step
If no: "What went wrong?"
If error: Debug â†’ Fix â†’ Retry

## Validation After All Steps

Run test command
WAIT for confirmation
Celebrate success ğŸ‰
```

---

## âš ï¸ Anti-Patrones (QuÃ© NO Hacer)

### âŒ **Anti-PatrÃ³n 1: Invocar Agentes sin Contexto**

**MAL**:

```markdown
## Step 1: Research

Use @library-researcher to find JWT best practices.
```

**BIEN**:

```markdown
## Step 1: Research with Full Context

Use @library-researcher to research JWT authentication:

**Context**:

- User wants to implement: $ARGUMENTS
- Project uses: [tech stack from analysis]
- Existing auth patterns: [summary from @codebase-analyst]

**Query**:
"Research JWT authentication best practices for [tech stack].

Focus:

1. Production-ready libraries (security track record)
2. Common pitfalls and how to avoid them
3. Testing strategies for JWT flows
4. Token refresh patterns

Constraints:

- Must integrate with existing auth in src/auth/
- Performance target: <50ms token validation

Output: `/research/research_jwt.md` with findings"
```

---

### âŒ **Anti-PatrÃ³n 2: Asumir AprobaciÃ³n en Checkpoints**

**MAL**:

```markdown
## Checkpoint

Present findings to user.

## Next Phase

Continue with implementation...
```

**BIEN**:

```markdown
## âœ… CHECKPOINT: Research Validation

Present findings:
```

[... summary ...]

Critical Questions:

1. [Question 1]
2. [Question 2]

Options: approve / fix: [desc] / restart

**WAIT FOR USER RESPONSE - Do NOT proceed without approval**

```

**IMPORTANT**: NEVER assume user approved. ALWAYS wait for explicit response.

## Next Phase (ONLY after "approve")

Continue with implementation...
```

---

### âŒ **Anti-PatrÃ³n 3: Comandos MonolÃ­ticos Sin Fases**

**MAL**:

```markdown
## Mission

Create feature, run tests, update docs, and deploy.

[Giant block of instructions without structure]
```

**BIEN**:

```markdown
## Mission

Implement feature with structured phases and validation.

## Phase 1: Research (30 min)

[...] â†’ CHECKPOINT 1

## Phase 2: Planning (20 min)

[...] â†’ CHECKPOINT 2

## Phase 3: Implementation (2 hrs)

[...] â†’ Validation gates after each task

## Phase 4: Documentation (15 min)

[...] â†’ Final validation
```

---

### âŒ **Anti-PatrÃ³n 4: Ignorar Capacidades de Agentes**

**MAL**:

```markdown
## Step 1

Read all files in src/ to understand patterns.
[Manual file reading with Read tool]
```

**BIEN**:

```markdown
## Step 1: Pattern Analysis

Use @codebase-analyst to systematically analyze patterns:

Query: "Analyze authentication patterns in src/auth/"

The agent will:

- Use serena find_symbol to find auth classes
- Use serena search_for_pattern to extract conventions
- Use serena get_symbols_overview for structure
- Consolidate into pattern summary

This is MUCH more efficient than manual file reading.
```

---

### âŒ **Anti-PatrÃ³n 5: Olvidar `allowed-tools` para Agentes**

**MAL**:

```markdown
---
description: "Command that invokes agents"
---

[Command invokes @library-researcher, but Task tool not in allowed-tools]
```

**BIEN**:

```markdown
---
description: "Command that invokes agents"
allowed-tools:
  - "Task" # CRÃTICO: Needed to invoke agents
  - "Read" # For reading files
  - "Write" # For creating outputs
  - "TodoWrite" # For tracking progress
---
```

---

### âŒ **Anti-PatrÃ³n 6: Descriptions Vagas en Frontmatter**

**MAL**:

```markdown
---
description: "Do stuff with code"
---
```

**BIEN**:

```markdown
---
description: "Research JWT authentication best practices and create implementation PRP"
---
```

La description es CRÃTICA porque es lo que Claude ve cuando decide si usar el comando via SlashCommand tool.

---

## ğŸ¯ Checklist de Calidad para Comandos Slash

### **Estructura BÃ¡sica**

- [ ] Frontmatter completo con `description`
- [ ] `argument-hint` si el comando espera argumentos
- [ ] `allowed-tools` incluye "Task" si invoca agentes
- [ ] Uso claro de `$ARGUMENTS`, `$1`, `$2` para parÃ¡metros
- [ ] Secciones organizadas: Usage, Arguments, Mission, Process

### **InvocaciÃ³n de Agentes**

- [ ] Agentes especificados explÃ­citamente (@nombre-agente)
- [ ] Contexto completo pasado a cada agente (no asumir conocimiento)
- [ ] Indica PARALELO o SECUENCIAL claramente
- [ ] WAIT statements antes de continuar despuÃ©s de agentes
- [ ] ConsolidaciÃ³n de resultados de mÃºltiples agentes

### **Checkpoints y ValidaciÃ³n**

- [ ] CHECKPOINT despuÃ©s de research (ROI 100x)
- [ ] CHECKPOINT despuÃ©s de planning (ROI 10-20x)
- [ ] Presenta opciones claras (approve/fix/restart)
- [ ] **WAIT FOR USER RESPONSE** explÃ­cito
- [ ] NUNCA asume aprobaciÃ³n, siempre espera respuesta

### **Manejo de Errores**

- [ ] Estrategia de error handling definida
- [ ] Retry logic con lÃ­mite (max 3 iterations)
- [ ] Fallback plan si stuck
- [ ] DocumentaciÃ³n de soluciones en memoria
- [ ] Debugging guidance para errores comunes

### **DocumentaciÃ³n de Outputs**

- [ ] Outputs guardados en estructura clara (/research/, /planning/, etc.)
- [ ] Formato consistente (markdown, YAML, etc.)
- [ ] Validation reports generados
- [ ] Memoria actualizada con learnings

### **Performance y Eficiencia**

- [ ] Uso de ejecuciÃ³n paralela cuando es seguro
- [ ] Time estimates incluidos por fase
- [ ] Context window management (<50% usage)
- [ ] ReutilizaciÃ³n de agentes existentes (no reinventar)

---

## ğŸ“Š ComparaciÃ³n: Antes vs DespuÃ©s

### **Comando ANTES de aplicar best practices**

```markdown
---
description: "Create feature"
---

# Create Feature

Use @library-researcher and @codebase-analyst to research.
Then create PRP.
Then execute PRP.
```

**Problemas**:

- âŒ No context para agentes
- âŒ No checkpoints
- âŒ No validation strategy
- âŒ No error handling
- âŒ No outputs definidos
- âŒ No parallel execution
- âŒ DescripciÃ³n vaga

---

### **Comando DESPUÃ‰S de aplicar best practices**

````markdown
---
description: "Research, plan, and implement feature with checkpoints and validation"
argument-hint: "feature-description"
allowed-tools: ["Read", "Write", "Edit", "Bash", "Task", "TodoWrite"]
---

# Command: create-feature-complete

## Usage

```bash
/create-feature-complete "Add payment processing with Stripe"
```
````

## Mission

Transform feature request into production-ready implementation with:

- Research phase (ROI 100x)
- Planning phase (ROI 10-20x)
- TDD implementation
- Multi-level validation

## Process (4 Phases, 2 Checkpoints)

### Phase 1: Research (45-60 min, PARALLEL)

**Context**:

- Feature request: $ARGUMENTS
- Project tech stack: [will be detected]

**Execute in PARALLEL**:

#### Agent 1: @library-researcher (~30 min)

Query: "Research best practices for implementing: $ARGUMENTS

Focus:

1. Production-ready libraries (security + maintenance)
2. Common pitfalls and solutions
3. Testing strategies
4. Integration patterns

Output: External best practices"

#### Agent 2: @codebase-analyst (~20 min)

Query: "Analyze existing patterns similar to: $ARGUMENTS

Find:

1. Naming conventions (classes, functions, files)
2. Code structure patterns
3. Integration patterns
4. Testing patterns

Output: Internal conventions"

**WAIT** for both agents to complete.

**Consolidate**: Create `/research/research_[feature].md`

### âœ… CHECKPOINT 1: Research Validation (ROI 100x)

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” RESEARCH COMPLETE - CHECKPOINT 1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“š FINDINGS SUMMARY:

**External Best Practices** (@library-researcher):
- [Practice 1]
- [Practice 2]
- [Critical Gotcha 1]

**Internal Patterns** (@codebase-analyst):
- Naming: [conventions]
- Structure: [patterns]
- Testing: [approach]

**Recommended Approach**:
[Synthesis of findings]

âš ï¸ CRITICAL QUESTIONS:

1. Does recommended approach align with your vision?
2. Any gotchas we missed?
3. Should we research anything else?
4. Is this direction correct?

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Options:
âœ… "approve" - Proceed to planning
ğŸ”„ "fix: [description]" - Adjust research
âŒ "restart" - Wrong direction, redo
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**WAIT FOR USER RESPONSE** - Do NOT proceed without approval.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**IF user responds "approve"**, continue. **IF "fix" or "restart"**, adjust and re-present.

### Phase 2: Planning (30-45 min)

Use @task-planner with Sequential Thinking:

Query: "Create detailed implementation plan for: $ARGUMENTS

Context:

- Research findings: [from Phase 1]
- Recommended approach: [from Checkpoint 1]

Output: Structured YAML plan with:

- Phases with atomic tasks
- Dependencies
- Validation commands
- Time estimates
- Success criteria"

**Output**: Create `/planning/planning_[feature].md`

### âœ… CHECKPOINT 2: Planning Validation (ROI 10-20x)

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ PLANNING COMPLETE - CHECKPOINT 2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ PLAN SUMMARY:

**Total Phases**: [N]
**Total Tasks**: [M]
**Estimated Time**: [X hours]

**Phase Breakdown**:
- Phase 1: [description] (~[Y] min)
- Phase 2: [description] (~[Z] min)
- ...

**Files to Create/Modify**:
- [file1]: [purpose]
- [file2]: [purpose]

**Dependencies to Add**:
- [package1]: [version] - [reason]
- [package2]: [version] - [reason]

âš ï¸ CRITICAL QUESTIONS:

1. Does file structure make sense?
2. Are tasks atomic enough?
3. Time estimates realistic?
4. Any missing steps?
5. Approve plan for execution?

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Options:
âœ… "approve" - Execute plan
ğŸ”„ "fix: [description]" - Adjust plan
âŒ "restart" - Redo planning
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**WAIT FOR USER RESPONSE** - Do NOT proceed without approval.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**IF user responds "approve"**, continue. **IF "fix" or "restart"**, adjust and re-present.

### Phase 3: TDD Implementation (2-4 hours)

Delegate to @task-executor:

Query: "Execute plan from: /planning/planning\_[feature].md

Approach:

- TDD: Write failing tests FIRST
- Implement: Minimum code to pass tests
- Validate: Use @validation-gates after EACH task
- Track: Update TodoList for progress

Stop if: Any validation fails (iterate until passes)

Output: Implemented feature with passing tests"

@task-executor will:

1. Parse YAML plan
2. Create TodoList from tasks
3. For each task:
   - Write failing test
   - Implement code
   - Run test (should pass)
   - Run @validation-gates
   - Mark complete
4. Report progress continuously

### Phase 4: Final Validation (30 min)

Use @validation-gates full suite:

```bash
# Level 1: Syntax
[linting command]

# Level 2: Style
[formatting command]

# Level 3: Tests
[test suite command]

# Level 4: Build
[build command]
```

**Success Criteria**: All 4 levels pass âœ…

### Phase 5: Documentation & Completion

Update documentation:

- README.md: Add feature usage
- CLAUDE.md: Update if architecture changed
- API docs: Document new endpoints/functions

Store learnings in memory:

- Pattern used: /`.claude/memories/pattern_[feature].md`
- Decisions made: `.claude/memories/decision_[feature].md`

Move plan to completed:

- `PRPs/completed/planning_[feature].md`

## Error Handling

### If Research Phase Fails

- Retry with more specific query
- Consult different sources
- Ask user for clarification
- Max 2 retries, then present partial findings

### If Planning Phase Fails

- Use Sequential Thinking to debug
- Simplify into smaller phases
- Consult @archon-expert for similar patterns
- Present adjusted plan for approval

### If Implementation Fails

- @validation-gates identifies exact failure
- Retry fix with @code-executor
- Max 3 retries per task
- If stuck: Present to user with analysis

### If Validation Fails

- Analyze failure reason
- Apply known fixes
- Document new solutions in memory
- Iterate until all levels pass

## Success Metrics

Feature is complete when:

- [ ] All tasks in plan executed
- [ ] All tests passing (100% of new code)
- [ ] All 4 validation levels pass
- [ ] Documentation updated
- [ ] Learnings stored in memory
- [ ] Plan moved to completed/

```

**Ventajas**:
- âœ… Full context para agentes
- âœ… 2 Checkpoints crÃ­ticos (ROI 100x + 10-20x)
- âœ… Validation strategy clara (4 levels)
- âœ… Error handling comprehensivo
- âœ… Outputs estructurados y documentados
- âœ… Parallel execution donde es seguro
- âœ… DescripciÃ³n accionable en frontmatter

---

## ğŸ”— Referencias y Recursos

### DocumentaciÃ³n Oficial
- [Claude Docs - Slash Commands](https://docs.claude.com/en/docs/claude-code/slash-commands)
- [Claude Code GitHub](https://github.com/anthropics/claude-code)

### Ejemplos en Este Proyecto
- `.claude/commands/init-project.md` - OrquestaciÃ³n compleja
- `.claude/commands/prp/prp-story-task-create.md` - Research command
- `.claude/commands/prp/prp-story-task-execute.md` - Execution command
- `.claude/agents/task-planner.md` - CoordinaciÃ³n de agentes
- `.claude/agents/prp-expert.md` - DelegaciÃ³n de tareas

### ArtÃ­culos y GuÃ­as
- [Claude Code Part 4 - Slash Commands](https://dev.to/letanure/claude-code-part-4-slash-commands-and-custom-commands-4fkf)
- [Practical Guide to Claude Code Slash Commands](https://www.eesel.ai/blog/claude-code-slash-commands)

---

## âœ… Conclusiones y PrÃ³ximos Pasos

### **Hallazgos Principales**

1. **No hay API directa para invocar agentes** - Se usan instrucciones en lenguaje natural
2. **Checkpoints son crÃ­ticos** - ROI 100x (research) y 10-20x (planning)
3. **Contexto completo es obligatorio** - Agentes no ven historial del usuario
4. **Parallel execution ahorra tiempo** - Cuando tareas son independientes
5. **Validation continua previene errores** - @validation-gates despuÃ©s de cada cambio
6. **SlashCommand tool tiene limitaciones** - 15k chars, no interactivo aÃºn
7. **Frontmatter es crucial** - `description` determina cuÃ¡ndo Claude usa comando

### **Patrones Validados**

| PatrÃ³n | Caso de Uso | ROI |
|--------|-------------|-----|
| Research (Parallel) | Investigar bibliotecas/features | 100x |
| Planning (Sequential Thinking) | DiseÃ±ar arquitectura | 10-20x |
| Execution (TDD + Validation) | Implementar feature | 5-10x |
| Interactive Setup | Configurar servicios | 3-5x |
| Validation Standalone | Verificar calidad | 2-3x |

### **Recomendaciones para el Proyecto**

#### **Comandos Existentes a Optimizar**

1. **`/prp:prp-story-task-create`**:
   - âœ… Ya usa parallel research (@library-researcher + @codebase-analyst)
   - âœ… Ya genera documento estructurado
   - âš ï¸ Falta CHECKPOINT explÃ­cito despuÃ©s de research
   - âš ï¸ PodrÃ­a usar Sequential Thinking para anÃ¡lisis profundo

2. **`/prp:prp-story-task-execute`**:
   - âœ… Ya tiene validaciÃ³n multi-nivel
   - âœ… Ya documenta deviations
   - âš ï¸ Falta error handling con retry logic explÃ­cito
   - âš ï¸ PodrÃ­a beneficiarse de auto-improvement loop

3. **`/init-project`**:
   - âœ… Excelente orquestaciÃ³n de agentes
   - âœ… Flujo interactivo bien diseÃ±ado
   - âœ… 2 Checkpoints implementados
   - âœ… Parallel execution usado
   - âš ï¸ `disable-model-invocation: true` podrÃ­a ser necesario (issue #4745)

#### **Nuevos Comandos Recomendados**

1. **`/create-feature-tdd`**: Feature completa con research â†’ planning â†’ TDD â†’ validation
2. **`/optimize-command [nombre]`**: Optimizar comando existente con best practices
3. **`/validate-command [nombre]`**: Validar que comando sigue best practices
4. **`/research-parallel [topic]`**: Research rÃ¡pido con @library-researcher + @codebase-analyst

### **PrÃ³ximos Pasos**

1. **Aplicar CHECKPOINTS** a comandos existentes que no los tienen
2. **Agregar `allowed-tools`** explÃ­citamente a todos los comandos
3. **Documentar error handling** en comandos complejos
4. **Crear templates** para tipos comunes de comandos
5. **Implementar auto-improvement loops** en comandos de validaciÃ³n
6. **Monitorear issue #4745** sobre SlashCommand tool interactivo

---

**Este documento serÃ¡ actualizado** conforme descubramos nuevos patrones o la API de Claude Code evolucione.

**VersiÃ³n**: 1.0
**Ãšltima ActualizaciÃ³n**: 2025-10-08
**Investigador**: @library-researcher
**Validado por**: Claude Code Template Team
```
