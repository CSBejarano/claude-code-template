# TÃ©cnicas Avanzadas de IngenierÃ­a de Contexto para Agentes de IA con Claude Code

## ğŸ“‹ Resumen Ejecutivo

Este documento resume las mejores prÃ¡cticas y tÃ©cnicas de ingenierÃ­a de contexto para maximizar el rendimiento de Claude Code, basado en la experiencia del equipo de BAML que logrÃ³ enviar miles de lÃ­neas de cÃ³digo de alta calidad diariamente.

---

## ğŸ¯ Principio Fundamental: GestiÃ³n del Context Window

**Regla de oro**: MantÃ©n el uso del context window al mÃ¡ximo 50% de capacidad (de 200k tokens disponibles).

### Â¿Por quÃ© es importante?

- Cada mensaje de usuario envÃ­a TODO el context window al modelo
- Cada llamada a herramientas envÃ­a TODO el context window
- Mayor contexto = menor densidad de informaciÃ³n Ãºtil = peor rendimiento

---

## ğŸ”„ Proceso de 3 Fases

### 1. **Research (InvestigaciÃ³n)**
- Usa sub-agentes para explorar diferentes partes del codebase en paralelo
- Genera un documento markdown (100-400 lÃ­neas) con hallazgos clave
- **Incluye**: paths exactos de archivos, nÃºmeros de lÃ­nea, flujo de informaciÃ³n
- **Revisa manualmente** este documento - es el punto de mayor leverage

**Ejemplo de prompt de investigaciÃ³n**:
```
Find everywhere in [feature/bug] relevant to solving this issue
and figure out how the information flows.
```

### 2. **Planning (PlanificaciÃ³n)**
- Crea un plan de implementaciÃ³n por fases basado en el research
- Especifica cambios exactos por archivo y nÃºmero de lÃ­nea
- Define tests a crear ANTES de implementar
- Incluye secciÃ³n "What we're NOT doing" para evitar scope creep

**Estructura del plan**:
- Fase 1: Cambios especÃ­ficos (archivo:lÃ­nea)
- Fase 2: Tests a agregar
- Fase 3: VerificaciÃ³n automatizada

### 3. **Implementation (ImplementaciÃ³n)**
- Con buen research y plan, la implementaciÃ³n es casi automÃ¡tica
- El agente puede trabajar con auto-accept activado
- EnfÃ³cate en revisar los tests, no tanto el cÃ³digo

---

## ğŸ¤– Sub-Agentes: Control de Contexto

**PropÃ³sito**: Los sub-agentes NO son para antropomorfizar, son SOLO para control de contexto.

### CuÃ¡ndo usar sub-agentes:

1. **BÃºsquedas en paralelo**: "Go find where X happens and where Y happens"
2. **Tareas independientes**: Escribir mÃºltiples tests unitarios
3. **InvestigaciÃ³n**: Cada sub-agente investiga una parte especÃ­fica

### Ventajas:
- Context window limpio y separado para cada tarea
- Resultados compactos y relevantes
- Las herramientas de bÃºsqueda no ensucian el context principal
- EjecuciÃ³n paralela

**Prompt Ã³ptimo**:
```
Use a sub-agent and prompt it like this: [instrucciones especÃ­ficas]
```

---

## ğŸ“¦ CompactaciÃ³n Intencional del Contexto

### Estrategias:

1. **Manual Compaction** (Mejor que /compact):
   ```
   Put everything we did so far in a markdown file
   so that an agent can pick up with the task
   ```

2. **Micro Compaction**: Elimina solo tool calls innecesarios

3. **Clear Context**: Inicia sesiÃ³n nueva con contexto limpio

4. **Estrategia recomendada**:
   - Compacta manualmente el progreso en archivo .md
   - Usa /clear para nueva sesiÃ³n
   - Lee el archivo compactado y continÃºa

---

## ğŸ§ª Test-Driven Development (TDD) con Agentes

**Regla crÃ­tica**: SIEMPRE usa TDD con agentes de IA.

### Por quÃ© TDD es esencial:

1. **VerificaciÃ³n automÃ¡tica**: El agente sabe si estÃ¡ correcto
2. **Menor revisiÃ³n humana**: Tests bien diseÃ±ados = cÃ³digo confiable
3. **Checkpoints claros**: Cada test es un punto de validaciÃ³n

### Mejores prÃ¡cticas:

- **Escribe tests PRIMERO**, luego el cÃ³digo
- AsegÃºrate de que los comandos de test sean triviales de ejecutar
- Usa nombres de test descriptivos para el LLM
- El agente debe poder ejecutar tests individuales fÃ¡cilmente

**Ejemplo de workflow**:
```
Phase 1: Write failing test
Phase 2: Implement feature
Phase 3: Verify test passes
```

---

## ğŸ“ Importancia de Revisar el Output

**JerarquÃ­a de impacto de errores**:

1. **Prompts base**: 1 error = 100,000 lÃ­neas malas
2. **Research**: 1 error = 1,000 lÃ­neas malas
3. **Plan**: 1 error = 10-100 lÃ­neas malas
4. **CÃ³digo**: 1 error = 1 lÃ­nea mala

### Proceso de revisiÃ³n del equipo:

1. âœ… **TODO** el equipo revisa el research
2. âœ… **TODO** el equipo revisa el plan
3. âš ï¸ RevisiÃ³n ligera del cÃ³digo
4. âœ… RevisiÃ³n detallada de los **tests**

**Workflow en Linear**:
```
To Do â†’ Research Needed â†’ Research in Progress â†’
Research in Review â†’ Ready for Plan â†’ Plan in Progress â†’
Plan in Review â†’ Ready for Dev â†’ In Dev â†’
Code Review â†’ Ready for Deploy
```

---

## ğŸ—ï¸ Arquitectura del Codebase

### Principios clave:

1. **Nomenclatura consistente**:
   - Usa los MISMOS nombres en todo el codebase
   - Evita 7 formas diferentes de llamar a lo mismo
   - "Field attributes" debe llamarse igual en TODAS partes

2. **Estructura de archivos clara**:
   - âŒ Evita: `page.tsx` en mÃºltiples carpetas (Next.js)
   - âœ… Prefiere: nombres de archivo Ãºnicos y descriptivos
   - Considera que el LLM ve una lista de paths, no una jerarquÃ­a visual

3. **Monorepo o links simbÃ³licos**:
   - Usa hard links (no symlinks) para que las herramientas de bÃºsqueda funcionen
   - Agrega directorios adicionales en settings.json de Claude Code

4. **Herramientas de build consistentes**:
   - Todos los comandos deben usar la misma herramienta (npm, bun, etc.)
   - Package.json con comandos claros y uniformes
   - Considera Turborepo para workspaces complejos

---

## âš™ï¸ ConfiguraciÃ³n y Herramientas

### VS Code + Claude Code:

1. **Terminal integrado**: Abre Claude Code en terminal integrado de VS Code
2. **ExtensiÃ³n de VS Code**: Instala la extensiÃ³n para acceso a LSP
3. **IntÃ©rprete correcto**: Selecciona el intÃ©rprete Python con librerÃ­as correctas
4. **Type checking**: Activa type checking en Python (off por defecto)

### Hooks y feedback loops:

1. **Claude Code Hooks**: Configura hooks para ejecutar linters automÃ¡ticamente
2. **LSP Errors Tool**: El agente puede obtener errores del IDE
3. **Automated verification**: Incluye comandos de verificaciÃ³n en el plan

### Claude.md:

âš ï¸ **IMPORTANTE**: El contenido de Claude.md viene con un disclaimer:
```
"This context may or may not be relevant to your task.
You should not respond to this context unless it is highly relevant."
```

**SoluciÃ³n**: Para instrucciones crÃ­ticas, ponlas:
- Directamente en el prompt
- En el plan de implementaciÃ³n
- NO solo en Claude.md

---

## ğŸ¨ MCP Tools: OptimizaciÃ³n

### Problemas comunes:

- Demasiados tools = context window lleno
- JSON ruidoso en respuestas
- InformaciÃ³n irrelevante

### Soluciones:

1. **Custom tools contexto-optimizados**:
   - Ejemplo: Tool de Linear que retorna markdown limpio
   - Comprime la informaciÃ³n antes de retornarla
   - Incluye solo datos relevantes

2. **Tool search/RAG**:
   - Para 10,000+ tools, implementa bÃºsqueda de tools
   - El agente busca quÃ© tool usar antes de ejecutar
   - Evita cargar todos los tools en el context window

3. **Limita tools por sesiÃ³n**:
   - Solo carga tools relevantes para la tarea actual

---

## ğŸ¯ TÃ©cnicas de Prompting Avanzadas

### Steering (DirecciÃ³n):

```
Only use read, glob, grep, search. Never bash
because bash requires permission.
```

### Extended Thinking:

```
Think deeply about [problema]
```
âš ï¸ Puede ser contraproducente - usa con cuidado

### IteraciÃ³n cuando falla:

1. Identifica por quÃ© fallÃ³
2. Crea un mejor prompt de research
3. Reinicia con contexto limpio
4. Usa compactaciÃ³n manual del intento fallido

### Especificidad de sub-agentes:

```
Use a task/sub-agent to: [tarea especÃ­fica]
Prompt it with: [instrucciones exactas]
Return: [formato especÃ­fico de respuesta]
```

---

## ğŸš€ Workflow PrÃ¡ctico Recomendado

### Para bugs/features pequeÃ±os:

1. Ir directo a Planning (skip Research)
2. El plan harÃ¡ research mÃ­nimo necesario
3. Si context > 80% despuÃ©s de research, reinicia con compactaciÃ³n

### Para features complejos:

1. **Research** (con sub-agentes paralelos)
2. Revisar y refinar research manualmente
3. **Planning** basado en research
4. Revisar plan en equipo
5. **Implementation** con auto-accept
6. Revisar tests ejecutados

### Regla de 10 minutos:

- Intenta con Claude Code por 10 minutos
- Si ves camino claro a completar en 30 min, continÃºa
- Si no, reinicia con nueva estrategia
- DespuÃ©s de 2 intentos, considera hacerlo manual

---

## ğŸ“Š MÃ©tricas de Ã‰xito

### Indicadores de buen workflow:

- âœ… Context window < 50% al implementar
- âœ… Tests pasan en primer intento
- âœ… Research identifica archivos correctos
- âœ… Plan tiene fases claras y ejecutables
- âœ… Equipo entiende los cambios sin leer cÃ³digo

### Red flags:

- âŒ Context window > 80%
- âŒ Research dice "no hay problema" cuando sÃ­ existe
- âŒ Plan vago sin nÃºmeros de lÃ­nea especÃ­ficos
- âŒ MÃºltiples iteraciones sin progreso
- âŒ Scope creep continuo

---

## ğŸ’¡ Tips Profesionales

### 1. **Reps, reps, reps**
- Practica constantemente para desarrollar intuiciÃ³n
- Como aprender un instrumento musical
- Experimenta con orden de prompts (Â¿contexto primero o pregunta primero?)

### 2. **Trata el agente como junior engineer**
- Cada nueva sesiÃ³n/sub-agente = nuevo empleado sin contexto
- Proporciona onboarding claro cada vez
- DocumentaciÃ³n y nomenclatura consistente es crÃ­tica

### 3. **EnfÃ³cate en lo de mayor leverage**
- Invierte tiempo en research y planning
- Menos tiempo revisando cÃ³digo
- Los tests son tu verificaciÃ³n principal

### 4. **Adapta tu codebase**
- Rust/Cargo funcionan excepcionalmente bien (TDD por defecto)
- TypeScript con Turbo es excelente
- Invierte en tooling que facilite testing automÃ¡tico

### 5. **Aprende de los fallos**
- Research incorrecto â†’ mejora el prompt de research
- Plan vago â†’ aÃ±ade mÃ¡s especificidad requerida
- CÃ³digo incorrecto â†’ mejora los tests primero

---

## ğŸ”— Recursos

- **Comandos open-source**: [Human Layer Terminal UI](https://github.com/BoundaryML/baml)
- **Research prompts**: 300+ lÃ­neas de markdown con sub-agent instructions
- **Planning prompts**: Estructura de fases con verification steps
- **Linear workflow**: To-do â†’ Research â†’ Plan â†’ Dev â†’ Deploy

---

## ğŸ“Œ Checklist RÃ¡pido

Antes de empezar una tarea con Claude Code:

- [ ] Â¿Tengo research si es complejo?
- [ ] Â¿Mi plan tiene nÃºmeros de lÃ­nea especÃ­ficos?
- [ ] Â¿Estoy escribiendo tests PRIMERO?
- [ ] Â¿Voy a usar sub-agentes para bÃºsquedas?
- [ ] Â¿Mi context window estÃ¡ < 50%?
- [ ] Â¿He configurado LSP y type checking?
- [ ] Â¿Mis nombres de archivos son Ãºnicos y descriptivos?
- [ ] Â¿Tengo comandos de test triviales?

---

## ğŸ“ ConclusiÃ³n

La ingenierÃ­a de contexto para agentes de IA es sobre:

1. **GestiÃ³n rigurosa del context window**
2. **Proceso estructurado** (Research â†’ Plan â†’ Implementation)
3. **TDD siempre** con agentes
4. **Review humano en puntos de alto leverage**
5. **Codebase optimizado** para LLMs
6. **PrÃ¡ctica constante** para desarrollar intuiciÃ³n

**Recuerda**: "Context engineering" no es diferente de escribir buenos prompts para LLMs - es aplicar los mismos principios a un flujo de trabajo de desarrollo completo.

---

*Basado en el podcast "Advanced Context Engineering for Coding Agents" - Episode #17*
